{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1YVu9fNsEzdBv2JvpYddKNod5tOtk0_sa","timestamp":1682137127007}],"toc_visible":true,"authorship_tag":"ABX9TyPSKn/8GdME8qkBhX2eo5Zs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tNjRjNfq4338","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682238922185,"user_tz":-60,"elapsed":216,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"ba4527c9-ac19-4824-d5b2-40297de00908"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converged in 1 iterations\n","Final weight vector: [ 0.8 -0.5]\n"]}],"source":["import numpy as np\n","\n","# Define the training samples\n","X = np.array([[1, 1], [-1, -1], [0, 0.5], [0.1, 0.5], [0.2, 0.2], [0.9, 0.5]])\n","y = np.array([1, -1, -1, -1, 1, 1])\n","\n","# Initialize the weight vector\n","w = np.array([1, 1])\n","\n","# Set the learning rate\n","lr = 1\n","\n","# Set the maximum number of iterations\n","max_iter = 100\n","\n","# Perceptron learning algorithm\n","iter = 0\n","while iter < max_iter:\n","    # Shuffle the training samples\n","    perm = np.random.permutation(X.shape[0])\n","    X = X[perm]\n","    y = y[perm]\n","\n","    # Iterate through each sample\n","    for i in range(X.shape[0]):\n","        # Compute the activation function\n","        fx = np.dot(w, X[i])\n","\n","        # If misclassified, update the weight vector\n","        if y[i]*fx <= 0:\n","            if y[i] == 1:\n","                w = w + lr*X[i]\n","            else:\n","                w = w - lr*X[i]\n","\n","    # Check if all samples are correctly classified\n","    if np.all(np.sign(np.dot(X, w)) == y):\n","        break\n","\n","    iter += 1\n","\n","# Print the results\n","print(\"Converged in\", iter, \"iterations\")\n","print(\"Final weight vector:\", w)\n"]}]}