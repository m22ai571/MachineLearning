{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO67FHVHwFUJKVm4OCElmS/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":138,"metadata":{"id":"tNjRjNfq4338","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682172388702,"user_tz":-60,"elapsed":2107,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"3ac41f20-8114-4a56-a131-21059cf321ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import cv2\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","def load_and_preprocess_data(data_dir):\n","    # Read the images and labels from the data directory\n","    train_images = []\n","    train_labels = []\n","    for subdir, _, files in os.walk(data_dir):\n","        for filename in files:\n","            if filename.endswith(\".bmp\") or filename.endswith(\".tiff\"): \n","                image_path = os.path.join(subdir, filename)\n","                image = load_image(image_path) \n","                label = os.path.basename(subdir)  # Use subdirectory name as label\n","                train_images.append(image)\n","                train_labels.append(label)\n","    \n","    # Convert lists to numpy arrays\n","    train_images = np.array(train_images)\n","    train_labels = np.array(train_labels)\n","    \n","    # Perform preprocessing on the images and labels\n","    train_images = preprocess_images(train_images)  # Replace with actual code to preprocess images\n","    train_labels = preprocess_labels(train_labels)  # Replace with actual code to preprocess labels\n","    \n","    return train_images, train_labels\n","\n","def load_image(image_path):\n","    image = cv2.imread(image_path)  # Load the image using OpenCV\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n","    image = cv2.resize(image, (28, 28))  # Resize the image to 28x28 pixels\n","    image = image.astype('float32') / 255.0  # Normalize the image values between 0 and 1\n","    image = np.expand_dims(image, axis=-1)  # Add a channel dimension to the image\n","    return image\n","\n","def preprocess_images(images):\n","    images = np.array(images)  # Convert the input images to a NumPy array\n","    images = images.astype('float32') / 255.0  # Normalize the pixel values between 0 and 1\n","    images = np.expand_dims(images, axis=-1)  # Add a channel dimension to the images\n","    return images\n","\n","def preprocess_labels(labels):\n","    labels = np.array(labels)  # Convert the input labels to a NumPy array\n","    labels = labels.astype('int64')  # Convert the label data type to int64\n","    return labels\n","\n","def get_label_from_filename(filename):\n","    label_str = filename.split(\".\")[0]\n","    label = int(label_str)\n","    return label\n"]},{"cell_type":"code","source":["train_images, train_labels = load_and_preprocess_data(\"/content/drive/My Drive/Colab Notebooks/Machine Learning/Assignment 2/Problem 2/train/\")  # Replace with actual code to load and preprocess data\n","train_images.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-IeOFDCEQH3","executionInfo":{"status":"ok","timestamp":1682172392042,"user_tz":-60,"elapsed":3342,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"9b67e229-d539-4033-ecdb-0f35fdbfa5c3"},"execution_count":139,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1000, 28, 28, 1, 1)"]},"metadata":{},"execution_count":139}]},{"cell_type":"code","source":["test_images, test_labels = load_and_preprocess_data(\"/content/drive/My Drive/Colab Notebooks/Machine Learning/Assignment 2/Problem 2/val/\")  # Replace with actual code to load and preprocess data\n","test_images.shape\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BuO-CR7QERPd","executionInfo":{"status":"ok","timestamp":1682172392488,"user_tz":-60,"elapsed":469,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"4802e93c-6a2d-47e2-e597-4b8b6f46d40e"},"execution_count":140,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(178, 28, 28, 1, 1)"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n","        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n","\n","    def call(self, inputs):\n","        x = self.flatten(inputs)\n","        x = self.dense1(x)\n","        return self.dense2(x)\n"],"metadata":{"id":"tlJmJ6b48Cdp","executionInfo":{"status":"ok","timestamp":1682172392488,"user_tz":-60,"elapsed":9,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}}},"execution_count":141,"outputs":[]},{"cell_type":"code","source":["\n","# Define the model architecture\n","\n","model = MyModel()\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(test_images, test_labels, epochs=200, batch_size=32)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udkYegjm8I42","executionInfo":{"status":"ok","timestamp":1682172433354,"user_tz":-60,"elapsed":40874,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"5b714044-86c9-4c84-ace9-c3ade97a751f"},"execution_count":142,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","6/6 [==============================] - 0s 31ms/step - loss: 2.3011 - accuracy: 0.1124\n","Epoch 2/200\n","6/6 [==============================] - 0s 30ms/step - loss: 2.2955 - accuracy: 0.2640\n","Epoch 3/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2905 - accuracy: 0.4719\n","Epoch 4/200\n","6/6 [==============================] - 0s 29ms/step - loss: 2.2849 - accuracy: 0.5281\n","Epoch 5/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2793 - accuracy: 0.4326\n","Epoch 6/200\n","6/6 [==============================] - 0s 34ms/step - loss: 2.2733 - accuracy: 0.3933\n","Epoch 7/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2668 - accuracy: 0.3764\n","Epoch 8/200\n","6/6 [==============================] - 0s 29ms/step - loss: 2.2601 - accuracy: 0.4663\n","Epoch 9/200\n","6/6 [==============================] - 0s 34ms/step - loss: 2.2526 - accuracy: 0.5169\n","Epoch 10/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.2448 - accuracy: 0.5225\n","Epoch 11/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2364 - accuracy: 0.4888\n","Epoch 12/200\n","6/6 [==============================] - 0s 33ms/step - loss: 2.2271 - accuracy: 0.5112\n","Epoch 13/200\n","6/6 [==============================] - 0s 29ms/step - loss: 2.2176 - accuracy: 0.5618\n","Epoch 14/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.2070 - accuracy: 0.6292\n","Epoch 15/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1967 - accuracy: 0.6236\n","Epoch 16/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1848 - accuracy: 0.6180\n","Epoch 17/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1727 - accuracy: 0.6517\n","Epoch 18/200\n","6/6 [==============================] - 0s 30ms/step - loss: 2.1597 - accuracy: 0.6629\n","Epoch 19/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.1465 - accuracy: 0.6180\n","Epoch 20/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1320 - accuracy: 0.6461\n","Epoch 21/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.1173 - accuracy: 0.6966\n","Epoch 22/200\n","6/6 [==============================] - 0s 32ms/step - loss: 2.1013 - accuracy: 0.7584\n","Epoch 23/200\n","6/6 [==============================] - 0s 30ms/step - loss: 2.0858 - accuracy: 0.7697\n","Epoch 24/200\n","6/6 [==============================] - 0s 30ms/step - loss: 2.0694 - accuracy: 0.7753\n","Epoch 25/200\n","6/6 [==============================] - 0s 27ms/step - loss: 2.0516 - accuracy: 0.7809\n","Epoch 26/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0339 - accuracy: 0.8090\n","Epoch 27/200\n","6/6 [==============================] - 0s 28ms/step - loss: 2.0158 - accuracy: 0.8090\n","Epoch 28/200\n","6/6 [==============================] - 0s 36ms/step - loss: 1.9980 - accuracy: 0.8034\n","Epoch 29/200\n","6/6 [==============================] - 0s 41ms/step - loss: 1.9776 - accuracy: 0.7978\n","Epoch 30/200\n","6/6 [==============================] - 0s 37ms/step - loss: 1.9582 - accuracy: 0.8258\n","Epoch 31/200\n","6/6 [==============================] - 0s 36ms/step - loss: 1.9391 - accuracy: 0.8315\n","Epoch 32/200\n","6/6 [==============================] - 0s 36ms/step - loss: 1.9174 - accuracy: 0.8427\n","Epoch 33/200\n","6/6 [==============================] - 0s 40ms/step - loss: 1.8972 - accuracy: 0.8427\n","Epoch 34/200\n","6/6 [==============================] - 0s 37ms/step - loss: 1.8753 - accuracy: 0.8427\n","Epoch 35/200\n","6/6 [==============================] - 0s 38ms/step - loss: 1.8533 - accuracy: 0.8483\n","Epoch 36/200\n","6/6 [==============================] - 0s 34ms/step - loss: 1.8325 - accuracy: 0.8258\n","Epoch 37/200\n","6/6 [==============================] - 0s 39ms/step - loss: 1.8100 - accuracy: 0.8258\n","Epoch 38/200\n","6/6 [==============================] - 0s 36ms/step - loss: 1.7872 - accuracy: 0.8315\n","Epoch 39/200\n","6/6 [==============================] - 0s 39ms/step - loss: 1.7646 - accuracy: 0.8371\n","Epoch 40/200\n","6/6 [==============================] - 0s 39ms/step - loss: 1.7420 - accuracy: 0.8483\n","Epoch 41/200\n","6/6 [==============================] - 0s 38ms/step - loss: 1.7195 - accuracy: 0.8596\n","Epoch 42/200\n","6/6 [==============================] - 0s 35ms/step - loss: 1.6968 - accuracy: 0.8539\n","Epoch 43/200\n","6/6 [==============================] - 0s 35ms/step - loss: 1.6753 - accuracy: 0.8539\n","Epoch 44/200\n","6/6 [==============================] - 0s 35ms/step - loss: 1.6517 - accuracy: 0.8539\n","Epoch 45/200\n","6/6 [==============================] - 0s 37ms/step - loss: 1.6296 - accuracy: 0.8652\n","Epoch 46/200\n","6/6 [==============================] - 0s 39ms/step - loss: 1.6062 - accuracy: 0.8764\n","Epoch 47/200\n","6/6 [==============================] - 0s 38ms/step - loss: 1.5839 - accuracy: 0.8708\n","Epoch 48/200\n","6/6 [==============================] - 0s 31ms/step - loss: 1.5614 - accuracy: 0.8708\n","Epoch 49/200\n","6/6 [==============================] - 0s 27ms/step - loss: 1.5392 - accuracy: 0.8652\n","Epoch 50/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.5174 - accuracy: 0.8708\n","Epoch 51/200\n","6/6 [==============================] - 0s 30ms/step - loss: 1.4961 - accuracy: 0.8764\n","Epoch 52/200\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4743 - accuracy: 0.8764\n","Epoch 53/200\n","6/6 [==============================] - 0s 27ms/step - loss: 1.4524 - accuracy: 0.8764\n","Epoch 54/200\n","6/6 [==============================] - 0s 30ms/step - loss: 1.4312 - accuracy: 0.8708\n","Epoch 55/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.4108 - accuracy: 0.8820\n","Epoch 56/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.3898 - accuracy: 0.8876\n","Epoch 57/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.3689 - accuracy: 0.8933\n","Epoch 58/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.3485 - accuracy: 0.8876\n","Epoch 59/200\n","6/6 [==============================] - 0s 30ms/step - loss: 1.3290 - accuracy: 0.8876\n","Epoch 60/200\n","6/6 [==============================] - 0s 31ms/step - loss: 1.3097 - accuracy: 0.8933\n","Epoch 61/200\n","6/6 [==============================] - 0s 31ms/step - loss: 1.2893 - accuracy: 0.8933\n","Epoch 62/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.2700 - accuracy: 0.8933\n","Epoch 63/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.2509 - accuracy: 0.8989\n","Epoch 64/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.2329 - accuracy: 0.8989\n","Epoch 65/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.2149 - accuracy: 0.8989\n","Epoch 66/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1962 - accuracy: 0.9045\n","Epoch 67/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1775 - accuracy: 0.9045\n","Epoch 68/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.1616 - accuracy: 0.8989\n","Epoch 69/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.1429 - accuracy: 0.8989\n","Epoch 70/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.1281 - accuracy: 0.9045\n","Epoch 71/200\n","6/6 [==============================] - 0s 30ms/step - loss: 1.1104 - accuracy: 0.9101\n","Epoch 72/200\n","6/6 [==============================] - 0s 28ms/step - loss: 1.0929 - accuracy: 0.9101\n","Epoch 73/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.0767 - accuracy: 0.9101\n","Epoch 74/200\n","6/6 [==============================] - 0s 30ms/step - loss: 1.0619 - accuracy: 0.9157\n","Epoch 75/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.0459 - accuracy: 0.9213\n","Epoch 76/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.0302 - accuracy: 0.9213\n","Epoch 77/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.0152 - accuracy: 0.9157\n","Epoch 78/200\n","6/6 [==============================] - 0s 29ms/step - loss: 1.0002 - accuracy: 0.9213\n","Epoch 79/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.9860 - accuracy: 0.9326\n","Epoch 80/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.9727 - accuracy: 0.9326\n","Epoch 81/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.9579 - accuracy: 0.9382\n","Epoch 82/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.9439 - accuracy: 0.9326\n","Epoch 83/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.9309 - accuracy: 0.9326\n","Epoch 84/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.9164 - accuracy: 0.9382\n","Epoch 85/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.9042 - accuracy: 0.9438\n","Epoch 86/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.8915 - accuracy: 0.9438\n","Epoch 87/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.8781 - accuracy: 0.9494\n","Epoch 88/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.8658 - accuracy: 0.9494\n","Epoch 89/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.8533 - accuracy: 0.9382\n","Epoch 90/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.8408 - accuracy: 0.9438\n","Epoch 91/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.8295 - accuracy: 0.9438\n","Epoch 92/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.8174 - accuracy: 0.9438\n","Epoch 93/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.8058 - accuracy: 0.9438\n","Epoch 94/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.7955 - accuracy: 0.9494\n","Epoch 95/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.7840 - accuracy: 0.9494\n","Epoch 96/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.7728 - accuracy: 0.9438\n","Epoch 97/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.7621 - accuracy: 0.9438\n","Epoch 98/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.7511 - accuracy: 0.9438\n","Epoch 99/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.7411 - accuracy: 0.9438\n","Epoch 100/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.7308 - accuracy: 0.9494\n","Epoch 101/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.7203 - accuracy: 0.9438\n","Epoch 102/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.7108 - accuracy: 0.9438\n","Epoch 103/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.7012 - accuracy: 0.9438\n","Epoch 104/200\n","6/6 [==============================] - 0s 41ms/step - loss: 0.6919 - accuracy: 0.9438\n","Epoch 105/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.6821 - accuracy: 0.9494\n","Epoch 106/200\n","6/6 [==============================] - 0s 37ms/step - loss: 0.6732 - accuracy: 0.9438\n","Epoch 107/200\n","6/6 [==============================] - 0s 37ms/step - loss: 0.6642 - accuracy: 0.9438\n","Epoch 108/200\n","6/6 [==============================] - 0s 36ms/step - loss: 0.6557 - accuracy: 0.9438\n","Epoch 109/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.6468 - accuracy: 0.9551\n","Epoch 110/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.6382 - accuracy: 0.9551\n","Epoch 111/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.6296 - accuracy: 0.9719\n","Epoch 112/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.6212 - accuracy: 0.9719\n","Epoch 113/200\n","6/6 [==============================] - 0s 43ms/step - loss: 0.6136 - accuracy: 0.9607\n","Epoch 114/200\n","6/6 [==============================] - 0s 37ms/step - loss: 0.6053 - accuracy: 0.9663\n","Epoch 115/200\n","6/6 [==============================] - 0s 37ms/step - loss: 0.5974 - accuracy: 0.9719\n","Epoch 116/200\n","6/6 [==============================] - 0s 36ms/step - loss: 0.5906 - accuracy: 0.9663\n","Epoch 117/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.5819 - accuracy: 0.9719\n","Epoch 118/200\n","6/6 [==============================] - 0s 42ms/step - loss: 0.5741 - accuracy: 0.9775\n","Epoch 119/200\n","6/6 [==============================] - 0s 40ms/step - loss: 0.5683 - accuracy: 0.9551\n","Epoch 120/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.5605 - accuracy: 0.9551\n","Epoch 121/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.5541 - accuracy: 0.9551\n","Epoch 122/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.5465 - accuracy: 0.9719\n","Epoch 123/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.5397 - accuracy: 0.9775\n","Epoch 124/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.5336 - accuracy: 0.9719\n","Epoch 125/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.5258 - accuracy: 0.9775\n","Epoch 126/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.5185 - accuracy: 0.9775\n","Epoch 127/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.5128 - accuracy: 0.9719\n","Epoch 128/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.5063 - accuracy: 0.9719\n","Epoch 129/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.5011 - accuracy: 0.9719\n","Epoch 130/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.4945 - accuracy: 0.9719\n","Epoch 131/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.4891 - accuracy: 0.9775\n","Epoch 132/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.4822 - accuracy: 0.9775\n","Epoch 133/200\n","6/6 [==============================] - 0s 34ms/step - loss: 0.4761 - accuracy: 0.9775\n","Epoch 134/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4708 - accuracy: 0.9719\n","Epoch 135/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.4647 - accuracy: 0.9719\n","Epoch 136/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4597 - accuracy: 0.9775\n","Epoch 137/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.4546 - accuracy: 0.9775\n","Epoch 138/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.4486 - accuracy: 0.9775\n","Epoch 139/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.4434 - accuracy: 0.9775\n","Epoch 140/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4383 - accuracy: 0.9775\n","Epoch 141/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.4330 - accuracy: 0.9775\n","Epoch 142/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.4280 - accuracy: 0.9775\n","Epoch 143/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.4232 - accuracy: 0.9775\n","Epoch 144/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.4182 - accuracy: 0.9775\n","Epoch 145/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4137 - accuracy: 0.9775\n","Epoch 146/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4086 - accuracy: 0.9775\n","Epoch 147/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.4038 - accuracy: 0.9775\n","Epoch 148/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3991 - accuracy: 0.9775\n","Epoch 149/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.3949 - accuracy: 0.9775\n","Epoch 150/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.3906 - accuracy: 0.9775\n","Epoch 151/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3855 - accuracy: 0.9719\n","Epoch 152/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3819 - accuracy: 0.9719\n","Epoch 153/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.3778 - accuracy: 0.9719\n","Epoch 154/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3726 - accuracy: 0.9775\n","Epoch 155/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3692 - accuracy: 0.9775\n","Epoch 156/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3654 - accuracy: 0.9775\n","Epoch 157/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3611 - accuracy: 0.9775\n","Epoch 158/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3568 - accuracy: 0.9775\n","Epoch 159/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.3528 - accuracy: 0.9831\n","Epoch 160/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.3492 - accuracy: 0.9888\n","Epoch 161/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.3448 - accuracy: 0.9888\n","Epoch 162/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3411 - accuracy: 0.9831\n","Epoch 163/200\n","6/6 [==============================] - 0s 27ms/step - loss: 0.3373 - accuracy: 0.9831\n","Epoch 164/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.3336 - accuracy: 0.9888\n","Epoch 165/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3299 - accuracy: 0.9888\n","Epoch 166/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3264 - accuracy: 0.9888\n","Epoch 167/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3232 - accuracy: 0.9888\n","Epoch 168/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3191 - accuracy: 0.9888\n","Epoch 169/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3158 - accuracy: 0.9888\n","Epoch 170/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3126 - accuracy: 0.9944\n","Epoch 171/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.3095 - accuracy: 0.9944\n","Epoch 172/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.3059 - accuracy: 0.9944\n","Epoch 173/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.3027 - accuracy: 0.9944\n","Epoch 174/200\n","6/6 [==============================] - 0s 28ms/step - loss: 0.2997 - accuracy: 0.9944\n","Epoch 175/200\n","6/6 [==============================] - 0s 36ms/step - loss: 0.2960 - accuracy: 1.0000\n","Epoch 176/200\n","6/6 [==============================] - 0s 42ms/step - loss: 0.2929 - accuracy: 1.0000\n","Epoch 177/200\n","6/6 [==============================] - 0s 40ms/step - loss: 0.2900 - accuracy: 0.9944\n","Epoch 178/200\n","6/6 [==============================] - 0s 35ms/step - loss: 0.2873 - accuracy: 0.9944\n","Epoch 179/200\n","6/6 [==============================] - 0s 35ms/step - loss: 0.2839 - accuracy: 0.9944\n","Epoch 180/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.2814 - accuracy: 0.9944\n","Epoch 181/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.2780 - accuracy: 0.9944\n","Epoch 182/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.2752 - accuracy: 0.9944\n","Epoch 183/200\n","6/6 [==============================] - 0s 40ms/step - loss: 0.2727 - accuracy: 0.9944\n","Epoch 184/200\n","6/6 [==============================] - 0s 37ms/step - loss: 0.2697 - accuracy: 0.9944\n","Epoch 185/200\n","6/6 [==============================] - 0s 40ms/step - loss: 0.2668 - accuracy: 0.9944\n","Epoch 186/200\n","6/6 [==============================] - 0s 46ms/step - loss: 0.2640 - accuracy: 0.9944\n","Epoch 187/200\n","6/6 [==============================] - 0s 40ms/step - loss: 0.2616 - accuracy: 0.9944\n","Epoch 188/200\n","6/6 [==============================] - 0s 39ms/step - loss: 0.2587 - accuracy: 0.9944\n","Epoch 189/200\n","6/6 [==============================] - 0s 38ms/step - loss: 0.2560 - accuracy: 0.9944\n","Epoch 190/200\n","6/6 [==============================] - 1s 111ms/step - loss: 0.2537 - accuracy: 1.0000\n","Epoch 191/200\n","6/6 [==============================] - 1s 112ms/step - loss: 0.2509 - accuracy: 1.0000\n","Epoch 192/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.2488 - accuracy: 1.0000\n","Epoch 193/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.2455 - accuracy: 0.9944\n","Epoch 194/200\n","6/6 [==============================] - 1s 104ms/step - loss: 0.2429 - accuracy: 0.9944\n","Epoch 195/200\n","6/6 [==============================] - 0s 36ms/step - loss: 0.2407 - accuracy: 0.9944\n","Epoch 196/200\n","6/6 [==============================] - 0s 31ms/step - loss: 0.2384 - accuracy: 1.0000\n","Epoch 197/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.2357 - accuracy: 1.0000\n","Epoch 198/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.2336 - accuracy: 1.0000\n","Epoch 199/200\n","6/6 [==============================] - 0s 29ms/step - loss: 0.2310 - accuracy: 1.0000\n","Epoch 200/200\n","6/6 [==============================] - 0s 30ms/step - loss: 0.2289 - accuracy: 0.9944\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8db4b94370>"]},"metadata":{},"execution_count":142}]},{"cell_type":"code","source":["test_loss, test_accuracy = model.evaluate(test_images, test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M1kbusYuKF9_","executionInfo":{"status":"ok","timestamp":1682172433807,"user_tz":-60,"elapsed":470,"user":{"displayName":"Mahesh Shivling Dongare (M22AI571)","userId":"10982997345224310338"}},"outputId":"dc7613d7-18a1-4066-bbc5-f1cd597de291"},"execution_count":143,"outputs":[{"output_type":"stream","name":"stdout","text":["6/6 [==============================] - 0s 12ms/step - loss: 0.2270 - accuracy: 0.9944\n"]}]}]}