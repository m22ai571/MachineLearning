{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tNjRjNfq4338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4ff5fe-81b4-46b2-a35b-73ccfdbfe004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def load_and_preprocess_data(data_dir):\n",
        "    # Read the images and labels from the data directory\n",
        "    train_images = []\n",
        "    train_labels = []\n",
        "    for subdir, _, files in os.walk(data_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".bmp\") or filename.endswith(\".tiff\"): \n",
        "                image_path = os.path.join(subdir, filename)\n",
        "                image = load_image(image_path) \n",
        "                label = os.path.basename(subdir)  # Use subdirectory name as label\n",
        "                train_images.append(image)\n",
        "                train_labels.append(label)\n",
        "    \n",
        "    # Convert lists to numpy arrays\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = np.array(train_labels)\n",
        "    \n",
        "    # Perform preprocessing on the images and labels\n",
        "    train_images = preprocess_images(train_images)  # Replace with actual code to preprocess images\n",
        "    train_labels = preprocess_labels(train_labels)  # Replace with actual code to preprocess labels\n",
        "    \n",
        "    return train_images, train_labels\n",
        "\n",
        "def load_image(image_path):\n",
        "    image = cv2.imread(image_path)  # Load the image using OpenCV\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert the image to grayscale\n",
        "    image = cv2.resize(image, (28, 28))  # Resize the image to 28x28 pixels\n",
        "    image = image.astype('float32') / 255.0  # Normalize the image values between 0 and 1\n",
        "    image = np.expand_dims(image, axis=-1)  # Add a channel dimension to the image\n",
        "    return image\n",
        "\n",
        "def preprocess_images(images):\n",
        "    images = np.array(images)  # Convert the input images to a NumPy array\n",
        "    images = images.astype('float32') / 255.0  # Normalize the pixel values between 0 and 1\n",
        "    images = np.expand_dims(images, axis=-1)  # Add a channel dimension to the images\n",
        "    return images\n",
        "\n",
        "def preprocess_labels(labels):\n",
        "    labels = np.array(labels)  # Convert the input labels to a NumPy array\n",
        "    labels = labels.astype('int64')  # Convert the label data type to int64\n",
        "    return labels\n",
        "\n",
        "def get_label_from_filename(filename):\n",
        "    label_str = filename.split(\".\")[0]\n",
        "    label = int(label_str)\n",
        "    return label\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = load_and_preprocess_data(\"/content/drive/My Drive/Colab Notebooks/Sem 2/Machine Learning/Assignment 2/Problem 2/train/\")  # Replace with actual code to load and preprocess data\n",
        "train_images.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-IeOFDCEQH3",
        "outputId": "77f53587-05b8-4973-d747-9c46b47928ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 28, 28, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_labels = load_and_preprocess_data(\"/content/drive/My Drive/Colab Notebooks/Sem 2/Machine Learning/Assignment 2/Problem 2/val/\")  # Replace with actual code to load and preprocess data\n",
        "test_images.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuO-CR7QERPd",
        "outputId": "aac2df0e-4a23-43b6-bb5c-b4220050b423"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178, 28, 28, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.flatten(inputs)\n",
        "        x = self.dense1(x)\n",
        "        return self.dense2(x)\n"
      ],
      "metadata": {
        "id": "tlJmJ6b48Cdp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the model architecture\n",
        "\n",
        "model = MyModel()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=200, batch_size=32)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udkYegjm8I42",
        "outputId": "8d63cb8a-d04f-426c-e642-d08fdc63d7d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "32/32 [==============================] - 1s 4ms/step - loss: 2.2932 - accuracy: 0.2590\n",
            "Epoch 2/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2628 - accuracy: 0.6440\n",
            "Epoch 3/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.2222 - accuracy: 0.6680\n",
            "Epoch 4/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 2.1649 - accuracy: 0.6820\n",
            "Epoch 5/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 2.0892 - accuracy: 0.7380\n",
            "Epoch 6/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.9959 - accuracy: 0.7980\n",
            "Epoch 7/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.8865 - accuracy: 0.7950\n",
            "Epoch 8/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.7672 - accuracy: 0.8320\n",
            "Epoch 9/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.6449 - accuracy: 0.7980\n",
            "Epoch 10/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.5242 - accuracy: 0.8300\n",
            "Epoch 11/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.4075 - accuracy: 0.8770\n",
            "Epoch 12/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.8960\n",
            "Epoch 13/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.2034 - accuracy: 0.8660\n",
            "Epoch 14/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 1.1100 - accuracy: 0.9070\n",
            "Epoch 15/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.9030\n",
            "Epoch 16/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.9515 - accuracy: 0.9110\n",
            "Epoch 17/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.8829 - accuracy: 0.9240\n",
            "Epoch 18/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.9160\n",
            "Epoch 19/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.7669 - accuracy: 0.9220\n",
            "Epoch 20/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.9280\n",
            "Epoch 21/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.9200\n",
            "Epoch 22/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.9370\n",
            "Epoch 23/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.9370\n",
            "Epoch 24/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5586 - accuracy: 0.9330\n",
            "Epoch 25/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.9360\n",
            "Epoch 26/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.9350\n",
            "Epoch 27/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.9370\n",
            "Epoch 28/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.9430\n",
            "Epoch 29/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.9380\n",
            "Epoch 30/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.9460\n",
            "Epoch 31/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3944 - accuracy: 0.9440\n",
            "Epoch 32/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3775 - accuracy: 0.9400\n",
            "Epoch 33/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.9440\n",
            "Epoch 34/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.9430\n",
            "Epoch 35/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3330 - accuracy: 0.9520\n",
            "Epoch 36/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.3213 - accuracy: 0.9460\n",
            "Epoch 37/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.9560\n",
            "Epoch 38/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.9500\n",
            "Epoch 39/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9530\n",
            "Epoch 40/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.9510\n",
            "Epoch 41/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.9560\n",
            "Epoch 42/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.9570\n",
            "Epoch 43/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9610\n",
            "Epoch 44/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9620\n",
            "Epoch 45/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.2390 - accuracy: 0.9640\n",
            "Epoch 46/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9560\n",
            "Epoch 47/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2255 - accuracy: 0.9620\n",
            "Epoch 48/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2185 - accuracy: 0.9610\n",
            "Epoch 49/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2147 - accuracy: 0.9610\n",
            "Epoch 50/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.2085 - accuracy: 0.9630\n",
            "Epoch 51/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9660\n",
            "Epoch 52/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1976 - accuracy: 0.9660\n",
            "Epoch 53/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1926 - accuracy: 0.9660\n",
            "Epoch 54/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1887 - accuracy: 0.9700\n",
            "Epoch 55/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1854 - accuracy: 0.9640\n",
            "Epoch 56/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1806 - accuracy: 0.9680\n",
            "Epoch 57/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1757 - accuracy: 0.9690\n",
            "Epoch 58/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1716 - accuracy: 0.9740\n",
            "Epoch 59/200\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.1692 - accuracy: 0.9730\n",
            "Epoch 60/200\n",
            "32/32 [==============================] - 0s 13ms/step - loss: 0.1657 - accuracy: 0.9740\n",
            "Epoch 61/200\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.1609 - accuracy: 0.9740\n",
            "Epoch 62/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1570 - accuracy: 0.9770\n",
            "Epoch 63/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1540 - accuracy: 0.9700\n",
            "Epoch 64/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1541 - accuracy: 0.9700\n",
            "Epoch 65/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9770\n",
            "Epoch 66/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 0.9780\n",
            "Epoch 67/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1417 - accuracy: 0.9790\n",
            "Epoch 68/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1393 - accuracy: 0.9790\n",
            "Epoch 69/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1368 - accuracy: 0.9810\n",
            "Epoch 70/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.1338 - accuracy: 0.9790\n",
            "Epoch 71/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1321 - accuracy: 0.9820\n",
            "Epoch 72/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9800\n",
            "Epoch 73/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9810\n",
            "Epoch 74/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1255 - accuracy: 0.9820\n",
            "Epoch 75/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9840\n",
            "Epoch 76/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9830\n",
            "Epoch 77/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9820\n",
            "Epoch 78/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9830\n",
            "Epoch 79/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9840\n",
            "Epoch 80/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9850\n",
            "Epoch 81/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9860\n",
            "Epoch 82/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.9860\n",
            "Epoch 83/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9870\n",
            "Epoch 84/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9860\n",
            "Epoch 85/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9860\n",
            "Epoch 86/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9860\n",
            "Epoch 87/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9890\n",
            "Epoch 88/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 0.9870\n",
            "Epoch 89/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9860\n",
            "Epoch 90/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9870\n",
            "Epoch 91/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0927 - accuracy: 0.9880\n",
            "Epoch 92/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0908 - accuracy: 0.9890\n",
            "Epoch 93/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9860\n",
            "Epoch 94/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9870\n",
            "Epoch 95/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9900\n",
            "Epoch 96/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0859 - accuracy: 0.9880\n",
            "Epoch 97/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9900\n",
            "Epoch 98/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0834 - accuracy: 0.9890\n",
            "Epoch 99/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0812 - accuracy: 0.9890\n",
            "Epoch 100/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9890\n",
            "Epoch 101/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0790 - accuracy: 0.9890\n",
            "Epoch 102/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9920\n",
            "Epoch 103/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9920\n",
            "Epoch 104/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9890\n",
            "Epoch 105/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9920\n",
            "Epoch 106/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9910\n",
            "Epoch 107/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9910\n",
            "Epoch 108/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9910\n",
            "Epoch 109/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0698 - accuracy: 0.9920\n",
            "Epoch 110/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0686 - accuracy: 0.9920\n",
            "Epoch 111/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0673 - accuracy: 0.9910\n",
            "Epoch 112/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0667 - accuracy: 0.9910\n",
            "Epoch 113/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9930\n",
            "Epoch 114/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0647 - accuracy: 0.9930\n",
            "Epoch 115/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9940\n",
            "Epoch 116/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9940\n",
            "Epoch 117/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0611 - accuracy: 0.9930\n",
            "Epoch 118/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0609 - accuracy: 0.9930\n",
            "Epoch 119/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9930\n",
            "Epoch 120/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9940\n",
            "Epoch 121/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9940\n",
            "Epoch 122/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9950\n",
            "Epoch 123/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9940\n",
            "Epoch 124/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9940\n",
            "Epoch 125/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9940\n",
            "Epoch 126/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9950\n",
            "Epoch 127/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9950\n",
            "Epoch 128/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0518 - accuracy: 0.9950\n",
            "Epoch 129/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0513 - accuracy: 0.9940\n",
            "Epoch 130/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0503 - accuracy: 0.9960\n",
            "Epoch 131/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9970\n",
            "Epoch 132/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9940\n",
            "Epoch 133/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0482 - accuracy: 0.9960\n",
            "Epoch 134/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9980\n",
            "Epoch 135/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9950\n",
            "Epoch 136/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9960\n",
            "Epoch 137/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0449 - accuracy: 0.9950\n",
            "Epoch 138/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9970\n",
            "Epoch 139/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9980\n",
            "Epoch 140/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9970\n",
            "Epoch 141/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0426 - accuracy: 0.9980\n",
            "Epoch 142/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9960\n",
            "Epoch 143/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9980\n",
            "Epoch 144/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9950\n",
            "Epoch 145/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9950\n",
            "Epoch 146/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9970\n",
            "Epoch 147/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0388 - accuracy: 0.9980\n",
            "Epoch 148/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9980\n",
            "Epoch 149/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 0.9970\n",
            "Epoch 150/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0372 - accuracy: 0.9980\n",
            "Epoch 151/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0363 - accuracy: 0.9980\n",
            "Epoch 152/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0356 - accuracy: 0.9980\n",
            "Epoch 153/200\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 0.9980\n",
            "Epoch 154/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9980\n",
            "Epoch 155/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9970\n",
            "Epoch 156/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0337 - accuracy: 0.9980\n",
            "Epoch 157/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0336 - accuracy: 0.9980\n",
            "Epoch 158/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0330 - accuracy: 0.9980\n",
            "Epoch 159/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0321 - accuracy: 0.9990\n",
            "Epoch 160/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9980\n",
            "Epoch 161/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0316 - accuracy: 0.9980\n",
            "Epoch 162/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0313 - accuracy: 0.9980\n",
            "Epoch 163/200\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 0.9980\n",
            "Epoch 164/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 0.9990\n",
            "Epoch 165/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0296 - accuracy: 0.9980\n",
            "Epoch 166/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0290 - accuracy: 0.9990\n",
            "Epoch 167/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9980\n",
            "Epoch 168/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9990\n",
            "Epoch 169/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0281 - accuracy: 0.9990\n",
            "Epoch 170/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0275 - accuracy: 0.9980\n",
            "Epoch 171/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0270 - accuracy: 0.9990\n",
            "Epoch 172/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0265 - accuracy: 0.9990\n",
            "Epoch 173/200\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0264 - accuracy: 0.9990\n",
            "Epoch 174/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0261 - accuracy: 0.9990\n",
            "Epoch 175/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9990\n",
            "Epoch 176/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0251 - accuracy: 0.9990\n",
            "Epoch 177/200\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0247 - accuracy: 0.9990\n",
            "Epoch 178/200\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0242 - accuracy: 0.9990\n",
            "Epoch 179/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9990\n",
            "Epoch 180/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9990\n",
            "Epoch 181/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9990\n",
            "Epoch 183/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9990\n",
            "Epoch 184/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0222 - accuracy: 0.9990\n",
            "Epoch 185/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9990\n",
            "Epoch 186/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0215 - accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9990\n",
            "Epoch 189/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0202 - accuracy: 0.9990\n",
            "Epoch 191/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6f3d072d60>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1kbusYuKF9_",
        "outputId": "a389e3bc-8cf0-451e-b489-5561e76a1a3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9551\n"
          ]
        }
      ]
    }
  ]
}